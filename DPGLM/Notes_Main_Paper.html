<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Notes on Hannah (2010) Paper</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="Notes_Main_Paper_files/libs/clipboard/clipboard.min.js"></script>
<script src="Notes_Main_Paper_files/libs/quarto-html/quarto.js"></script>
<script src="Notes_Main_Paper_files/libs/quarto-html/popper.min.js"></script>
<script src="Notes_Main_Paper_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Notes_Main_Paper_files/libs/quarto-html/anchor.min.js"></script>
<link href="Notes_Main_Paper_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Notes_Main_Paper_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Notes_Main_Paper_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Notes_Main_Paper_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Notes_Main_Paper_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Notes on Hannah (2010) Paper</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="intro-and-nomenclature-notes" class="level2">
<h2 class="anchored" data-anchor-id="intro-and-nomenclature-notes">Intro and Nomenclature Notes</h2>
<p>Regular regression setup. Response <span class="math inline">\(Y\)</span> and covariates <span class="math inline">\(X \in \mathbb{R}^d\)</span>. Then <span class="math inline">\(Y \mid X \sim f(m(X))\)</span> where <span class="math inline">\(m(\cdot)\)</span> is some deterministic mean function.</p>
<p><span class="math inline">\(m\)</span> specifies the conditional mean of the response, and <span class="math inline">\(f\)</span> is a distribution. <span class="math inline">\(f\)</span> characterizes the deviation of the response from the conditional mean. e.g.&nbsp;<span class="math inline">\(m(X) = X\)</span> and <span class="math inline">\(f(X) = \beta_0 + X \beta\)</span> (I think).</p>
<p>Regardless, they define the ‘data set’ as <span class="math inline">\(\{(x_i, y_i)\}_{i = 1}^N\)</span>. Given new set of covariates <span class="math inline">\(x_{\text{new}}\)</span>, the prediction is <span class="math inline">\(\hat{y} = \mathbb{E}[Y \mid x_{\text{new}}]\)</span>. In Bayesian regression we do all of this with the <em>posterior expectation</em>.</p>
</section>
<section id="what-the-dpglm-does" class="level2">
<h2 class="anchored" data-anchor-id="what-the-dpglm-does">What the DPGLM does</h2>
<p>It produces a regression model by modeling the joint distribution of the covariates and the response.</p>
<p>Specificaly, this is done using a Dirichlet process mixture model.</p>
<ul>
<li><p>For each observation, a hidden parameter <span class="math inline">\(\theta\)</span> is draw</p></li>
<li><p>Covariates are generated from a parametric distribution conditioned on <span class="math inline">\(\theta\)</span></p></li>
<li><p>Them the response is drawn from a GLM conditioned on the covariates and <span class="math inline">\(\theta\)</span></p></li>
</ul>
<p>Like DPMMs, this is an infinite mixture model. Also like DPMMs, it identifies local regions of patterns.</p>
</section>
<section id="dpmm-mathematical-background-review" class="level2">
<h2 class="anchored" data-anchor-id="dpmm-mathematical-background-review">DPMM Mathematical Background (Review)</h2>
<p>In a Bayesian mixture model we assume the true joint density of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> can be written as a mixture of parametric densities, such as Gaussians or multinomials, conditioned on a hidden parameter <span class="math inline">\(\theta\)</span>. E.g., <span class="math inline">\(\theta\)</span> includes mean and variance for a Normal mixture.</p>
<p>In the DPGLM, <span class="math inline">\(\theta\)</span> is split into two parts. <span class="math inline">\(\theta_x\)</span>, which is associated only with the covariates <span class="math inline">\(X\)</span>, and <span class="math inline">\(\theta_y\)</span> which is associated only with the response <span class="math inline">\(y\)</span>. Thus <span class="math inline">\(\theta = (\theta_x, \theta_y)\)</span> and the <strong>marginal probability</strong> of an observation is the continuous mixture</p>
<p><span class="math display">\[
f_0(x,y) = \int_{\mathcal{T}} f(x, y\mid\theta)P(d \theta)
\]</span> Where <span class="math inline">\(\mathcal{T}\)</span> is the set of all possible parameters and the prior <span class="math inline">\(P\)</span> is a probability measure on the space <span class="math inline">\(\mathcal{T}\)</span> .</p>
<p>The Dirichlet process models uncertainty about the prior density <span class="math inline">\(P\)</span>.</p>
<p>If <span class="math inline">\(P\)</span> is drawn from a DP then it can be integrated out of the conditional distribution of <span class="math inline">\(\theta_n\)</span> given <span class="math inline">\(\theta_{1:(n-1)}\)</span>. In this case, the random variable <span class="math inline">\(\Theta_n\)</span> takes a Polya Urn Distribution.</p>
<p><span class="math display">\[
\Theta_n \mid \theta_{1:(n-1)} \sim \frac{1}{\alpha + n -1} \sum_{i = 1}^{n - 1} \delta_{\theta_{i}} + \dfrac{\alpha}{\alpha + n - 1}\mathbb{G}_{0} \tag{1}
\]</span> ### Side-Note: Blackwell - MacQueen Polya Urn Scheme</p>
<p>In the above, we assume that <span class="math inline">\(\Theta_1, \theta_2, \dots \Theta_{n-1} \sim \text{DP}(\alpha, \mathbb{G}_0)\)</span> which are <em>iid</em> draws from a DP with concentration <span class="math inline">\(\alpha\)</span> and base measure <span class="math inline">\(\mathbb{G}_0\)</span>.</p>
<p>Essentially what Equation <span class="math inline">\(1\)</span> says is that with probability <span class="math inline">\(1 / (\alpha + n - 1)\)</span>, <span class="math inline">\(\Theta_n\)</span> takes the value of one of the previously drawn <span class="math inline">\(\theta_i\)</span>’s and with probability <span class="math inline">\(1 / (\alpha + n - 1)\)</span> it is drawn from the Base Measure <span class="math inline">\(\mathbb{G}_0\)</span>.</p>
<p>In the above, <span class="math inline">\(\delta_{\theta_i}\)</span> is the Dirac delta measure, which places all of its mass at the point <span class="math inline">\(\theta_i\)</span>. In the above, the sum of Dirac measures creates a probability distribution over the previous <span class="math inline">\(\theta_i\)</span>’s. For example, <span class="math inline">\(1/(n-1) \sum_{i = 1}^{n-1} \delta_{\theta_i}\)</span> would provide uniform probability to select any previous <span class="math inline">\(\theta_i\)</span>. But, this is rescaled with respect to the DP parameter <span class="math inline">\(\alpha\)</span> to allow for the <span class="math inline">\(\alpha / (\alpha + n - 1)\)</span> chance of sampling from the base measure <span class="math inline">\(\mathbb{G}_0\)</span> while remaining a valid probability distribution. (The sum of <span class="math inline">\(n - 1\)</span> deltas has mass <span class="math inline">\((n - 1)/(\alpha + n - 1)\)</span> which is the chance <span class="math inline">\(\Theta_n\)</span> is some previous theta. Then, each specific <span class="math inline">\(\theta_i\)</span> has individual probability <span class="math inline">\(1/(\alpha + n - 1)\)</span> of being chosen as <span class="math inline">\(\Theta_n\)</span>)</p>
<section id="r-demo" class="level3">
<h3 class="anchored" data-anchor-id="r-demo">R Demo</h3>
<p>We can quickly incorporate the Blackwell-MacQueen sampler / Polya Urn distribution as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># predictive distribution of a DP</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>blackwell_macqueen_sampler <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha, <span class="at">g0 =</span> <span class="cf">function</span>() <span class="fu">rnorm</span>(<span class="dv">1</span>)) {</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  theta <span class="ot">&lt;-</span> <span class="fu">numeric</span>(N)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  theta[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">g0</span>()  <span class="co"># theta_1 = G0</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># then, construct iteratively</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>N) {</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    p_new <span class="ot">&lt;-</span> alpha <span class="sc">/</span> (alpha <span class="sc">+</span> n <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> p_new) {</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>      <span class="co"># sample new value from G0</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>      theta[n] <span class="ot">&lt;-</span> <span class="fu">g0</span>()</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>      <span class="co"># sample uniformly from existing theta_1, ..., theta_{n-1}</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>      theta[n] <span class="ot">&lt;-</span> <span class="fu">sample</span>(theta[<span class="dv">1</span><span class="sc">:</span>(n <span class="sc">-</span> <span class="dv">1</span>)], <span class="at">size =</span> <span class="dv">1</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(theta)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">blackwell_macqueen_sampler</span>(<span class="at">N =</span> <span class="dv">100</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>freqs <span class="ot">&lt;-</span> (<span class="fu">table</span>(samples) <span class="sc">/</span> <span class="fu">length</span>(samples))</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>theta_n <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">val =</span> <span class="fu">as.numeric</span>(<span class="fu">rownames</span>(freqs)),</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>                      <span class="at">prb =</span> <span class="fu">as.numeric</span>(freqs))</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># theta_n # realization of RV \Theta_n</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(theta_n, <span class="fu">aes</span>(<span class="at">x =</span> val, <span class="at">y =</span> prb)) <span class="sc">+</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> val, <span class="at">xend =</span> val, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">yend =</span> prb), <span class="at">color =</span> <span class="st">"steelblue"</span>) <span class="sc">+</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">2</span>, <span class="at">color =</span> <span class="st">"steelblue"</span>) <span class="sc">+</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Polya-Urn Realization of Dirichlet Process with Standard Normal Base Measure"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Notes_Main_Paper_files/figure-html/blackwellmacqueen-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="understanding-the-paramaterization" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-paramaterization">Understanding the Paramaterization</h2>
<p>In the above, the <em>unique</em> <span class="math inline">\(\theta_{1:n}\)</span> are drawn from the base measure <span class="math inline">\(\mathbb{G}_0\)</span>. Hence, Even though the full sequence <span class="math inline">\(\{\theta_{i}\}_{i = 1}^n\)</span> is not i.i.d., the unique values are. The clustering comes about because each <span class="math inline">\(\theta_j\)</span> has some nonzero probability to take a previous <span class="math inline">\(\theta_{i &lt; j}\)</span> as its value. Further, the concentration parameter <span class="math inline">\(\alpha\)</span> controls how likely <span class="math inline">\(\Theta_n\)</span> is to be drawn from <span class="math inline">\(\mathbb{G}_0\)</span> rather than a previously-realized <span class="math inline">\(\theta_{1:n}\)</span>.</p>
<p>In a Dirichlet Process <em>Mixture</em>, each <span class="math inline">\(\theta\)</span> is a latent parameter to an observed data point <span class="math inline">\(x\)</span>, i.e. <span class="math display">\[
\begin{aligned}
P &amp;\sim \text{DP}(\alpha, \mathbb{G}_0) \\
\Theta_i &amp;\sim P, \text{ for } i \in[1, n] \\
x_i \mid \theta_i &amp;\sim f( \cdot \mid \theta_i) , \text{ for } i \in[1, n]
\end{aligned}
\]</span> Here, <span class="math inline">\(P\)</span> is a discrete probability measure which takes a DP prior, from base measure <span class="math inline">\(\mathbb{G}_0\)</span>. Each <span class="math inline">\(\theta_i\)</span> is a latent variable drawn from <span class="math inline">\(P\)</span>. Because <span class="math inline">\(P\)</span> is discrete, multiple <span class="math inline">\(\theta_i\)</span>’s will share the same value which allows for clustering.</p>
</section>
<section id="generalized-linear-models" class="level2">
<h2 class="anchored" data-anchor-id="generalized-linear-models">Generalized Linear Models</h2>
<p>GLMs relate a linear model to a potentially nonlinear response via a link function, i.e.&nbsp;logistic, Poisson or multinomial regression links.</p>
<p>Generally, GLMs have three components. The conditional probability model for <span class="math inline">\(Y\)</span>, the linear predictor and the link function.</p>
<p>The probability model for <span class="math inline">\(Y\)</span>, dependent on the covariates <span class="math inline">\(X\)</span>, is therefore:</p>
<p><span class="math display">\[
f(y\mid \eta) = \exp \bigg( \dfrac{y \eta - b(\eta)}{a(\phi)} + c(y, \phi) \bigg)
\]</span> Where the above is the canonical form of the exponential family, and <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> are known functions specific to the exponential family (the scaling function, dispersion and normalizing functions respectively), <span class="math inline">\(\theta\)</span> is an arbitrary dispersion parameter and <span class="math inline">\(\eta\)</span> is the canonical parameter (a function of the predictors in GLMs).</p>
<p>In the above, <span class="math inline">\(\mathbb{E}[Y] = b^{\prime}(\eta)\)</span> and <span class="math inline">\(\text{var}(Y) = a(\phi)b^{\prime \prime}(\eta)\)</span>.</p>
<section id="using-the-general-exponential-family-form" class="level3">
<h3 class="anchored" data-anchor-id="using-the-general-exponential-family-form">Using the General Exponential Family form</h3>
<p>The canonical exponential family form gives a common framework for modeling different kinds of data (Gaussian, Poisson, Bernoulli, etc.) that come from exponential families.</p>
<p>For example, if we let <span class="math inline">\(\eta = \mu\)</span>, <span class="math inline">\(b(\eta) = \eta^2/2 = \mu^2/2\)</span>, <span class="math inline">\(a(\phi) = \sigma^2\)</span> and <span class="math inline">\(c(y, \phi) = - \frac{y^2}{2\sigma^2} - \frac{1}{2}\log(2\pi \sigma^2)\)</span> we have… <span class="math display">\[
\begin{aligned}
f(y \mid \eta) &amp;= \exp \bigg( \dfrac{y \eta - b(\eta)}{a(\phi)} + c(y, \phi) \bigg) \\
&amp;= \exp \bigg( \dfrac{y \mu - \frac{\mu^2}{2}}{\sigma^2} + c(y, \phi) \bigg) \\
&amp;= \exp \bigg( \frac{1}{2\sigma^2}(2 y \mu -\mu^2) + c(y, \phi) \bigg) \\
&amp;= \exp \bigg( \frac{1}{2\sigma^2}(2 y \mu -\mu^2) - \frac{y^2}{2\sigma^2} - \frac{1}{2}\log(2\pi \sigma^2) \bigg) \\
&amp;=  \dfrac{1}{\exp(\frac{1}{2}\log(2\pi \sigma^2))}\exp \bigg( -\frac{1}{2\sigma^2}(y^2 -2 y \mu +\mu^2)\bigg) \\
&amp;= \dfrac{1}{\sqrt{2 \pi \sigma^2}}\exp\Big( -\frac{1}{2\sigma^2}(y-\mu)^2 \Big)
\end{aligned}
\]</span> Which is the exact density of <span class="math inline">\(y \sim \mathcal{N}(\mu, \sigma^2)\)</span>.</p>
<p>Further, the mean is what we’d expect. <span class="math display">\[
\mathbb{E}[Y] = b^{\prime}(\eta) = \dfrac{\text{d}}{\text{d}\eta}\big( \frac{\eta^2}{2}\big) = \eta_{\,\big| \,\eta = \mu} = \mu
\]</span> As is the variance. <span class="math display">\[
\text{var}[Y] = a(\phi)  b^{\prime\prime}(\eta)= \sigma^2\cdot \dfrac{\text{d}^2}{\text{d}^2\eta}\big( \frac{\eta^2}{2}\big) = \sigma^2
\]</span></p>
</section>
<section id="connection-to-glms" class="level3">
<h3 class="anchored" data-anchor-id="connection-to-glms">Connection to GLMs</h3>
<p>In a GLM, <span class="math inline">\(\eta\)</span> is estimated by <span class="math inline">\(X\boldsymbol{\beta}\)</span> through a set of transformations. It can be shown that, in this case, <span class="math inline">\(b^{\prime}(\eta) = \mu = \mathbb{E}[Y \mid X]\)</span>. However, you can also find/choose a link function <span class="math inline">\(g\)</span> such that <span class="math inline">\(\mu = g^{-1}(X\boldsymbol{\beta})\)</span> that defines <span class="math inline">\(\eta\)</span> solely in terms of <span class="math inline">\(X\boldsymbol{\beta}\)</span>.</p>
<p>The flexible nature of GLMs allows us to use them as a local approximation for a global response function.</p>
</section>
</section>
<section id="the-dirichlet-process-mixture-of-generalized-linear-models" class="level2">
<h2 class="anchored" data-anchor-id="the-dirichlet-process-mixture-of-generalized-linear-models">The Dirichlet Process Mixture of Generalized Linear Models</h2>
<p>In the DP-GLM, the authors allow the covariates <span class="math inline">\(X\)</span> to be modeled by a mixture of exponential-family distributions and the response <span class="math inline">\(Y\)</span> to be modeled by a GLM conditioned on the inputs. Beyond this, the models are connected by associating a set of GLM coefficients with each exponential family mixture component.</p>
<p>Let <span class="math inline">\(\theta = (\theta_x, \theta_y)\)</span> denote the bundle of parameters over <span class="math inline">\(X\)</span> and <span class="math inline">\(Y \mid X\)</span>. Let <span class="math inline">\(\mathbb{G}_0\)</span> de a base measure on the space of both.</p>
<p>For instance, <span class="math inline">\(\theta_x\)</span> might be a set of <span class="math inline">\(d\)</span>-dimensional multivariate Gaussian location <span class="math inline">\(\mu\)</span> and scale <span class="math inline">\(\sigma\)</span> parameters for a vector <span class="math inline">\(\vec{\mathbf{x}}\)</span> of continuous covariates, and <span class="math inline">\(\theta_y\)</span> could be a <span class="math inline">\(d + 2\)</span> dimensional vector for their corresponding GLM linear prediction coefficients <span class="math inline">\(\beta\)</span> along with a GLM dispersion parameter <span class="math inline">\(\phi\)</span>.</p>
<p>The full model is, in this case, for <span class="math inline">\(i \in[1, n]\)</span> <span class="math display">\[
\begin{aligned}
P &amp;\sim \text{DP}(\alpha, \mathbb{G}_0) \\
(\theta_{x,i} , \theta_{y, i}) \mid P &amp;\sim P\\
X_i \mid \theta_{x,i} &amp;\sim f_x( \cdot \mid \theta_{x,i})  \\
Y_i \mid x_i, \theta_{y,i} &amp;\sim \text{GLM}(\cdot \mid x_i, \theta_{y,i})
\end{aligned}
\]</span> The density <span class="math inline">\(f_x\)</span> describes the covariate distribution. The GLM for <span class="math inline">\(y\)</span> depends on the form of the response (continuous, count, category, etc.) and how the response relates to the covariates (by the link function).</p>
<p>The DP clusters the covariate-response pairs <span class="math inline">\((x,y)\)</span>. When both are observed (in training), the posterior distribution of this model will cluster data points according to nearby covariates that have the same kind oof relationship as their response.</p>
<p>When the response is <em>unobserved</em> (in testing), its predictive expectation can be understood by clustering the covariates based on training ata, and then predicting the response according to the GLM associated with the covariates’ cluster.</p>
<p>The DP prior also acts as a kernel for the covariates. It measures the distance between two points by the probability that the hidden measure is shared.</p>
<section id="worked-example-gaussian-model" class="level3">
<h3 class="anchored" data-anchor-id="worked-example-gaussian-model">Worked Example: Gaussian Model</h3>
<p>Let us suppose we have continuous covariates and response variables in <span class="math inline">\(\mathbb{R}\)</span>. In such a case, we model locally with a gaussian distribution.</p>
<p>The <span class="math inline">\(i\)</span>-th covariate has mean <span class="math inline">\(\mu_{i,j}\)</span> and variance <span class="math inline">\(\sigma^2_{i,j}\)</span> for the <span class="math inline">\(j\)</span>-th dimension (<span class="math inline">\(j \in [1,d]\)</span>), and the VCV is diagonal for simplicity.</p>
<p>The parameters of the GLM are linear predictors <span class="math inline">\(\beta_{i0}, \dots \beta_{id}\)</span> with response variance <span class="math inline">\(\sigma^2_{i, y}\)</span>.</p>
<p>Here, then, <span class="math inline">\(\theta_{x,i} = (\mu_{i, 1:d}, \sigma_{i, 1:d})\)</span> and <span class="math inline">\(\theta_{y, i} = (\beta_{i, 0:d}, \sigma_{i, y}\)</span> where <span class="math inline">\(\theta_i = (\theta_x, \theta_y)\)</span>. This produces a mixture of multivariate Gaussian random variables. The full model here is…</p>
<p><span class="math display">\[
\begin{aligned}
\mathcal{P} &amp;\sim \text{DP}(\alpha, \mathbb{G}_0) \\
\Theta_i \mid \mathcal{P}  &amp;\sim \mathcal{P} \\
X_i \mid \theta_{x,i} &amp;\sim \mathcal{N}(\mu_{ij}, \sigma^2_{ij}), \text{ where } \theta_{x,i} =  \big( \mu_{i, j}, \sigma_{i, j}\big)_{j = 1}^d \\
Y_i \mid x_i, \theta_{y,i} &amp;\sim \mathcal{N}\Big(\beta_{i0} + \sum_{j =1}^d\beta_{ij}x_{ij}, \sigma^2_{iy}\Big), \text{ where } \theta_{y,i} =  \big( \{\beta_{i, j}\}_{j=0}^d, \sigma_{i, y}\big)
\end{aligned} \tag{2}
\]</span></p>
</section>
<section id="dp-glm-regression" class="level3">
<h3 class="anchored" data-anchor-id="dp-glm-regression">DP-GLM Regression</h3>
<p>The authors write how the DP-GLM is used in prediction problems. Namely, given a collection of covariate response pairs <span class="math inline">\((x_i, y_i)_{i=1}^n\)</span>, their goal is to compute the expected response for a new set of covariates. Conditional on the latent parameters that generated the observed data, <span class="math inline">\(\theta_{1:n}\)</span>, the theoretical expectation of the response is: <span class="math display">\[
\mathbb{E}[Y \mid x, \theta_{1:n}] = \frac{\alpha}{b}\int_{\mathcal{T}} \mathbb{E}[Y \mid x, \theta] f_x(x\mid \theta) \mathbb{G}_0(\text{d} \theta) + \frac{1}{b}\sum_{i=1}^n \mathbb{E}[Y\mid x, \theta_i]f_x(x \mid \theta_i) \tag{3}
\]</span> The first term is the product of the expectation of the GLM at <span class="math inline">\(x\)</span> and <span class="math inline">\(\theta \in \mathcal{T}\)</span>, the likelihood of <span class="math inline">\(x\)</span> given <span class="math inline">\(\theta\)</span> and the probability density of <span class="math inline">\(\theta\)</span> under the base measure. It is the term accounting for all possible parameters under the base measure to the expectation. The second term is the product of the expectation of the GLM across the observed parameters <span class="math inline">\(\theta_{i}\)</span>, <span class="math inline">\(i \in [1,n]\)</span>.</p>
<p>In the above, <span class="math inline">\(b\)</span> is the normalizing constant <span class="math display">\[
b = \alpha \int_{\mathcal{T}}f_x(x\mid \theta) \mathbb{G}_0(\text{d} \theta) + \sum_{i=1}^n f_x(x \mid \theta_i)
\]</span> Where <span class="math inline">\(\mathcal{T}\)</span> is the set of all possible parameters.</p>
</section>
<section id="towards-sampling" class="level3">
<h3 class="anchored" data-anchor-id="towards-sampling">Towards Sampling…</h3>
<p>As <span class="math inline">\(\theta_{1:n}\)</span> is not actually known, the unobserved random variables are integrated out of Equation <span class="math inline">\(3\)</span> using the <em>posterior</em> distribution given the observed data.</p>
<p>Let <span class="math inline">\(\Pi^{\mathcal{P}}\)</span> denote the DP prior on the set of hidden parameter measures, <span class="math inline">\(\mathcal{P}\)</span>. Let <span class="math inline">\(\mathcal{M}_{\mathcal{T}}\)</span> be the space of <em>all</em> distributions over the hidden parameters.</p>
<p>The authors note that since <span class="math inline">\(\int_{\mathcal{T}}f_y(y|x, \theta)f_x(x|\theta)\mathcal{P}(\text{d}\theta)\)</span> is a density for joint <span class="math inline">\((x,y)\)</span> that <span class="math inline">\(\Pi^{\mathcal{P}}\)</span>induces a prior on <span class="math inline">\(\mathcal{F}\)</span>, the set of <em>all</em> densities <span class="math inline">\(f\)</span> on <span class="math inline">\((x,y)\)</span>. They denote this prior <span class="math inline">\(\Pi^{f}\)</span> with posterior distribution: <span class="math display">\[
\Pi^f_n(A) = \dfrac{\int_{A} \prod_{i =1}^n f(X_i, Y_i) \Pi^f(\text{d}f)}{\int_{\mathcal{F}} \prod_{i =1}^n f(X_i, Y_i) \Pi^f(\text{d}f)}
\]</span> Where <span class="math inline">\(A \subseteq \mathcal{F}\)</span>. Similarly <span class="math inline">\(\Pi_n^{\mathcal{P}}\)</span> is defined (for some subset of <span class="math inline">\(\mathcal{P}\)</span>.)</p>
<p>The regression is then <span class="math display">\[
\begin{aligned}
\mathbb{E}[Y|x, (X_i, Y_i)_{i=1}^n] = &amp;\frac{1}{b}\sum_{i = 1}^n \int_{\mathcal{M}_{\mathcal{T}}}\int_{\mathcal{T}}\mathbb{E}[Y|x, \theta_i]f_x(x|\theta_i)\mathcal{P}(\text{d}\theta_i)\Pi_n^{\mathcal{P}}(\text{d}\mathcal{P}) \\
&amp;+ \frac{\alpha}{b}\int_{\mathcal{T}} \mathbb{E}[Y|x, \theta]f_x(x|\theta)\mathbb{G}_0(\text{d}\theta)
\end{aligned} \tag{4}
\]</span> Where <span class="math inline">\(b\)</span> normalizes the probability of <span class="math inline">\(Y\)</span> being associated with the parameter <span class="math inline">\(\theta_i\)</span>.</p>
<p>The above is nearly impossible to compute in practice because it requires integration over a hidden random measure. Thus, it is approximated by the average of <span class="math inline">\(M\)</span> Monte Carlo samples of the expectation conditioned on <span class="math inline">\(\theta_{1:n}^{(m)}\)</span></p>
<p><span class="math display">\[
\boxed{\mathbb{E}[Y|x, (X_i, Y_i)_{i = 1}^n] \approx \dfrac{1}{M}\sum_{m = 1}^M \mathbb{E} \Big[ Y|x,\theta^{(m)}_{1:n} \Big]} \tag{5}
\]</span></p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>
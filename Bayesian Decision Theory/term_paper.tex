\documentclass[letterpaper,12pt]{article}
%% Always use 12pt - it is much easier to read
%% Things written after '%' sign, are ignored by the latex editor - they are how to
%% Anything mathematics related should be put in between '$' signs.
%% Set some names and numbers here so we can use them below
\newcommand{\myname}{} %%%%%%%%%%%%%%% ---------> 
\newcommand{\mynumber}{Caden Hewlett}
\newcommand{\hw}{} 
%% There is a bit of stuff below which you should not have to change
%%%%%%
%% AMS mathematics packages - they contain many useful fonts and symbols.
\usepackage{amsmath, amsfonts, amssymb, array, xcolor}
%% The geometry package changes the margins to use more of the page, I suggest
%% using it because standard latex margins are chosen for articles and letters,
%% not homework.
\usepackage[paper=letterpaper,left=25mm,right=25mm,top=3cm,bottom=25mm]{geometry}
%% For details of how this package work, google the ``latex geometry
%%
%% Fancy headers and footers - make the document look nice
\usepackage{fancyhdr} %% for details on how this work, search-engi
\usepackage{framed}
\usepackage{mathalpha}
\usepackage{natbib}

\pagestyle{fancy}
%%
%% The header
\lhead{Philosophy 321} % course name as top-left
\chead{Term Paper} % homework number in top-centre
\rhead{ \myname \\ \mynumber }
%% This is a little more complicated because we have used `` \\ '' to force a line
%%
%% The footer
\lfoot{\myname} % name on bottom-left
\cfoot{Page \thepage} % page in middle
\rfoot{\mynumber} % student number on bottom-right
%%
%% These put horizontal lines between the main text and header and footer.
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
%%%
% Some useful macros
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{upgreek}
\usepackage{bbm}
\usepackage{hyperref}
\usepackage{setspace}
\newcommand{\ZZ}{\mathbb{Z}}
\usepackage{placeins}
\newcommand{\FF}{\mathbb{F}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\ddx}{\dfrac{\text{d}}{\text{d}x}}
\renewcommand\vec{\mathbf}
\newcommand{\st}{\text{ s.t. } }
\newcommand{\dee}[1]{\mathrm{d}#1}
\newcommand{\diff}[2]{ \frac{\dee{#1}}{\dee{#2}} }
\newcommand{\lt}{<}
\newcommand{\gt}{>}
\newcommand{\set}[1]{\left\{#1 \right\}}
\newcommand{\dig}[1]{\left\langle{#1}\right\rangle}
\newcommand{\closure}[1]{\overline{#1}}
\newcommand{\interior}[1]{\mathrm{int}\left(#1\right)}
\newcommand{\boundary}[1]{\delta\left(#1\right)}
\newcommand{\ceiling}[1]{\left\lceil #1 \right\rceil}
\newcommand{\given}{|}

% Begin document
\begin{document}
	\doublespacing
	
\textit{Introduction}: In progress...

\textit{Background}: To introduce the nomenclature, we let $\mathcal{X}$ be the observation space, representing all possible data you might observe. Further, we let ${\Theta}$ be the parameter space, capturing all conceivable ``states of nature." Finally, we let $\mathcal{A}$ be the action space, consisting of all actions or estimators you can choose in response to the observed data. For this paper, an action $a \in \mathcal{A}$ generally implies estimating $\theta \in \Theta$ with a certain formula $\upalpha(x)$ known as the \textit{estimator}. For simplicity, we allow all of these spaces to be discrete. The observations $x \in \mathcal{X}$ are connected to the parameter $\theta \in \Theta$ by the probability mass function $p(x \given \theta)$, referred to as the data-generating process (DGP) \cite{tu2004data}. In a discrete setting, the DGP describes the probability of an observation $x \in \mathcal{X}$ under a given parameter $\theta$. The primary objective of statistical inference is to infer underlying properties of the DGP \cite{upton2008oxford}. From a decision-theoretic perspective, the decision $a \in \mathcal{A}$ will propose a function $\upalpha(x)$ to estimate the parameter $\theta$ as precisely as possible. To illustrate this concept, suppose we are flipping a fair coin and wish to recover the parameter $\theta$ corresponding to the proportion of heads, $\theta = 0.5$. Thus, the DGP $p(x \given \theta)$ is a Bernoulli distribution with parameter $\theta$. One action $a_1 \in \mathcal{A}$ is to propose the estimator $\upalpha_1(x) = \frac{1}{n}\sum_{i = 1}^n x_i$ (where $n$ is the number of flips) whereas $a_2 \in \mathcal{A}$ is to naively propose $\upalpha_2 (x) = 1$ (every flip is heads). It can be shown\footnote{ Given $p(x\given \theta) = \prod_{i = 1}^n\theta^{x_i}(1-\theta)^{1-x_i}$, the log-likelihood of the $n$ observations is $\ell(x, \theta) = \log(\theta) \sum_{i = 1}^n x_i + \log(1 - \theta) \sum_{i = 1}^n (1 - x_i)$. Maximizing wrt $\theta$ yields $\hat{\theta}_{\text{MLE}} = \frac{1}{n}\sum_{i = 1}^n x_i = \upalpha_1(x)$.} that $a_1$ proposes an estimator which maximizes the likelihood of the observed data under the DGP \cite{rossi2018}, whereas $a_2$'s estimator is biased, thus trivially $a_1 \succ a_2$. Unless necessarily distinct, we henceforth use estimators $\upalpha$ and the actions $a$ proposing them interchangeably. 

To quantify the preference orderings beyond the simple heuristics mentioned in the coin-flipping case, statisticians leverage loss functions  \cite{wald1950}, which we denote $\mathcal{L}(\theta, \upalpha)$. The loss function represents the error associated with proposing a ``bad" estimation of the $\theta$ (or function of $\theta$) of interest. Thus, the best evaluation of this function is a zero loss; therefore, $\mathcal{L}(\theta, \upalpha) \geq 0$ \cite{robert2007bayesian}. From a decision-theoretic perspective, the objective of the decision-maker is to propose an estimator $\upalpha$ which minimizes this loss. Since the actual value of parameter $\theta$ is often unknown, statisticians base their ordering of estimators on the \textit{expected} loss. However, precisely how we define \textit{expected} relies upon whether one takes a {frequentist} or {Bayesian} approach. 

\textit{Frequentism and Minimax}: Under the frequentist paradigm, the data $x \in \mathcal{X}$ are considered random because they arise from repeated sampling via the DGP $p(x \given \theta)$. Meanwhile, $\theta$ is treated as a fixed but unknown constant in the parameter space $\Theta$. In the coin-flipping example, a frequentist would assume that the coin has a fixed (unknown) probability $\theta$ of landing heads, and thus $p(x\given \theta)$ governs each flip outcome. Thus, to evaluate a proposed estimator $\upalpha$, the frequentist approach focuses on expected loss, akin to how Peterson \cite{peterson2017} considers the expected utility. Specifically, we define the expected loss (EL) as the product of the probability of observing $x \in \mathcal{X}$ and the loss associated with estimating $\theta$ with $\upalpha(x)$,
\begin{equation}
	\text{EL}(\theta, \upalpha) = \mathbb{E}_{\theta}[\mathcal{L}(\theta, \upalpha)] = \sum_{x \in \mathcal{X}} \mathcal{L}\big( \theta, \upalpha(x) \big) p(x \given \theta)  \label{eq:EL}
\end{equation}
Other works refer to the above as a risk function \cite{nikulin2001}. From this definition of expected loss, we introduce the concept of ``minimax" through a game-theoretic analogy of a game against Nature. In this framework, our goal is to select an estimator $\upalpha \in \mathcal{A}$ that \textit{minimizes} our expected loss. Meanwhile, Nature acts as an adversary, selecting a parameter $\theta \in \Theta$ (i.e., a ``state of the world") in an attempt to \textit{maximize} our expected loss \cite{ulansky2021}. The expected loss in such a game is known as the ``minimax risk", which we define as
\begin{equation}
	\overline{{R}} = \min_{\upalpha \in \mathcal{A}}\bigg\{ \max_{\theta \in \Theta} \bigg\{ \text{EL}(\theta, \upalpha) \bigg\} \bigg\} \label{eq:minimaxrisk}
\end{equation}
The minimax estimator is known as the estimator/decision rule $\upalpha \in \mathcal{A}$ that achieves the minimax risk. While the minimax risk $\overline{R}$ is occasionally criticized as being overly conservative \cite{peterson2017}, the ability of an estimator to be the best in the worst case scenario (which we refer to as the ``minimax guarantee") is desirable for many real-world applications including management of financial portfolios \cite{DENG2005278}.

Having defined the minimax risk in \hyperref[eq:minimaxrisk]{Equation (2)} and the corresponding guarantee, we now turn to \textit{The Bayesian Choice}Â \cite{robert2007bayesian}, in which Christian Robert demonstrates that under the ``least favourable" prior, Bayesian decision theory achieves a Bayes risk that is at least as good (and often better than) the frequentist minimax bound. We first introduce the notion of a \textit{prior} to explain the Bayesian paradigm. In a discrete parameter space, the prior is a function $\uppi: \Theta \mapsto [0,1] \subseteq \mathbb{R}$ satisfying $\sum_{\theta \in \Theta} \uppi (\theta) = 1$ where $\uppi(\theta)$ is the probability that $\theta$ is the ``true" state of the world. In other words, a Bayesian would say that ``$\theta$ follows a $\uppi$-distribution \textit{a priori}." In this framework the data $x \in \mathcal{X}$ still arise from the DGP $p(x \given \theta)$ (now known as the ``likelihood") but are treated as \textit{fixed} once observed. Bayesian methods instead place uncertainty in $\theta$, initially via $\uppi(\theta)$ and later in $\uppi(\theta \given x)$, the \textit{a posteriori} distribution of $\theta$, after observing $x$. In contrast, frequentist methods conceptualize $x \in \mathcal{X}$ as potentially variable under repeated sampling, while $\theta$ is fixed but unknown.


In Decision Theory, to evaluate a proposed estimator $\upalpha \in \mathcal{A}$, the Bayesian approach focuses on the posterior expected loss (PEL). This PEL averages the loss $\mathcal{L}(\theta, \upalpha(x))$ across all possible values of $\theta \in \Theta$ and is weighted by the posterior probability of the parameter $\uppi(\theta \given x)$ conditioned on the observed value $x$. 
\begin{equation}
		\text{PEL}(\uppi, \upalpha \given x) = \mathbb{E}_{\uppi}[\mathcal{L}(\theta, \upalpha)\given x] = \sum_{\theta \in \Theta} \mathcal{L}(\theta, \upalpha(x)) \uppi(\theta \given x)
\end{equation}
The equation above considers the weighted loss across all $\theta \in \Theta$ for a singular $x$, whereas \hyperref[eq:EL]{Equation (1)} weighs across all $x \in \mathcal{X}$ for a singular $\theta$; thus, the two measures are not necessarily commensurable. To enable direct comparison between the Bayesian framework and the frequentist paradigm, Robert introduces the notion of Integrated Risk and Bayes Risk\footnote{Note that formal definitions of Bayes Risk date as far back as the 1980s with works from James O. Berger\cite{berger1985}. Robert himself cites these works as part of his argument.}. The Integrated Risk is the frequentist risk averaged over the values of $\theta$ according to their prior distribution $\uppi(\theta)$. Integrated risk is useful for comparing estimators due to the fact that it associates a real number with every estimator, while the posterior expected loss varies with $x$. Formally, we write the integrated risk as:
\begin{equation}
 {r}(\uppi, \upalpha) = \sum_{\theta \in \Theta} \text{EL}(\theta, \upalpha)  \uppi(\theta) = \sum_{\theta \in \Theta}\sum_{x \in \mathcal{X}} \mathcal{L}\big(\theta, \upalpha(x) \big)p(x \mid \theta) \uppi(\theta)  \label{eq:IR}
\end{equation}
It may not seem immediately obvious how weighing the frequentist loss according to the prior $\uppi(\theta)$ fully captures the Bayesian approach. However, in his essay Robert proves that selecting an estimator $\upalpha \in \mathcal{A}$ which minimizes the purely-Bayesian posterior expected loss (see \hyperref[eq:PEL]{Equation 3}) \textit{also} minimizes the integrated risk \cite{robert2007bayesian}. Specifically, he demonstrates that summing across (or integrating) the posterior expected loss with respect to the marginal distribution of $x$ is equivalent to computing the integrated risk defined above. From this fact, he argues that the `purely' Bayesian approach, although conditional on observed data, is mathematically justified even by frequentist standards. This is due in part to the fact that it also incorporates the probabilistic properties of the data-generating process $p(x \given \theta)$, as the previous definition shows. From this, Robert argues that the Bayesian approachâthough conditional on observed dataâis justified even by frequentist standards, since it yields estimators that minimize overall (integrated) risk. To support his view that the Bayesian approach is \textit{superior} to the frequentist paradigm, Robert discusses the \textit{best} estimator (and its associated risk) for \hyperref[eq:IR]{Equation 4}, which he demonstrates outperforms the \hyperref[eq:minimaxrisk]{frequentist minimax risk} defined earlier. Such an estimator is known as the \textit{Bayes estimator}. For a given prior distribution $\uppi$ and a loss function $\mathcal{L}$, the Bayes estimator $\upalpha^{\uppi}(x)$ minimizes the posterior expected loss for every observation $x \in \mathcal{X}$. Consequently, it minimizes the overall integrated risk. From a constructive standpoint, the Bayes estimator can be defined by minimizing \hyperref[eq:PEL]{Equation 3} for each observation, i.e.
$$
\forall x \in \mathcal{X}, \,\upalpha^{\uppi}(x) = \underset{\upalpha \in \mathcal{A}}{\text{argmin}} \, \bigg[\sum_{\theta \in \Theta} \mathcal{L}(\theta, \upalpha(x)) \uppi(\theta \given x)\bigg]
$$
Because $\upalpha^{\uppi}$ minimizes the point-wise PEL for each $x$, it follows that $r(\uppi, \upalpha^{\uppi})$ is also the minimal integrated risk for all $\upalpha \in \mathcal{A}$. This minimum value is known as the \textit{Bayes Risk}. 



% "not necessarily as dangerous as frequentists may depict it"
\textit{Remaining Work}
\begin{enumerate}\item{Introduce Robert's Argument and proof. (Bayesianism (done), Posterior Expected Loss (done), Integrated Risk (done), Bayes Risk, proof of Bayes Risk $\leq$ Minimax Risk using weighted sum vs. set maxima)} 
\item{Introduce Stark's Counterargument: How the prior $\pi(\theta)$ is subjective, and Robert's proof is trivial since you are ``adding information" to the risk problem which was previously constrained by objectivity.}
\item{Introduce the Bayesian Rebuttal: Namely, the subjectivity of choice of loss function $\mathcal{L}(\dots)$ implies the frequentist construction of the problem isn't operating under such ``objective constraints," so given that subjective claims need to be made on the state of Nature, a Bayesian approach gives provable optimality. }
\item{Conclusion and Introduction }
 \end{enumerate}
 %Formally, by examining how integrated Bayesian risk can match the worst-case criterion, Robertâs analysis shows that Bayesian decision theory is âat least as goodâ as the frequentist minimax approach, yet retains the interpretive benefits of a prior-based framework.
%% transition into Christian Robertâs book The Bayesian Choice, in which he uses minimaxity of integrated bayesian risk as an argument in favour of a Bayesian decision-theoretic approach over a frequentist one. 
%  Christian Robertâs book The Bayesian Choice
% Robert' section:
% Intro to bayesian philosophy (what is random what isn't)
% Connection to coin example again
% Introduce integrated risk (maybe posterior expected loss)
%% Frequentist risk averaged over the values of theta according to their posterior distribution
% Introduce Bayes Estimator (Definition 2.3.3)
%% and Bayes risk as r(\pi) = r(\pi, \alpha_{\text{B}})
%% r(\pi, \alpha) = \sum_{\theta \in \Theta}\sum_{x \in \mathcal{X}} \mathcal{L}\big(\theta, \alpha(x) \big)p_{\mathcal{X}\mid\Theta}(x \mid \theta) p_{\Theta}(\theta)
%% or using pi notation
%% \alpha_{\text{B}} = \underset{ {\alpha \in \mathcal{A}} }{\text{argmin}}\sum_{\theta \in \Theta}\sum_{x \in \mathcal{X}} \mathcal{L}\big(\theta, \alpha(x) \big)p_{\mathcal{X}\mid\Theta}(x \mid \theta) \pi(\theta) \\
% Demonstrate using least favourable prior that
% the Bayes risk is always smaller than the minmax risk
%% \max_{\pi \in \Pi}r(\pi, \alpha_{\text{B}}) \leq R(\theta, \overline{\alpha}_{\text{F}})
% using weighted sum <= maximum
% making a decision based on the expected value of the loss function; 
%  represents the loss (or error) owing to a bad evaluation of the function of Î¸ of interest, and therefore that even the best evaluation of this function, i.e.,
% when Î¸ is known, can induce at best a null loss.
\bibliographystyle{unsrt}
\bibliography{final_paper_bib}  
% Introduce Minimax Risk
%% Introduce minimax estimator
%% \overline{\alpha}_{\text{F}} = \text{argmin}_{\alpha \in \mathcal{A}} \max_{\theta \in \Theta}\sum_{x \in \mathcal{X}}\mathcal{L}(\theta , \alpha(x))f(x\mid \theta)
%% "minimax guarantee" in the worst-case scenario


\end{document}
